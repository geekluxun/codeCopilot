{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import Dict, Union, Any, Optional, List, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import Trainer\n",
    "from transformers import TrainerCallback"
   ],
   "id": "860e911f84624cdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PrinterCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            print(logs)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MyTrainer(Trainer):\n",
    "    def prediction_step(\n",
    "            self,\n",
    "            model: nn.Module,\n",
    "            inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "            prediction_loss_only: bool,\n",
    "            ignore_keys: Optional[List[str]] = None,\n",
    "    ) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "        return super().prediction_step(model, inputs, prediction_loss_only, ignore_keys)"
   ],
   "id": "51355af9009bc3cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "hf_hub_download(repo_id=\"Qwen/Qwen2-7B\")"
   ],
   "id": "ad70d6610c69b7d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"  # 或你的模型路径\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, cache_dir=\"./ca\")\n"
   ],
   "id": "1a55404443a559de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!huggingface-cli download meta-llama/Llama-2-7b-hf --output-dir ./local_model",
   "id": "7742625b7981e5fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "330abf3ac590a89f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
